#+title: Notes on Meyer's Matrix Analysis and Applied Linear Algebra
#+author: Marian Domanski
#+date: <2025-09-06 Sat>
#+language: en
#+startup: latexpreview
#+startup: show2levels

* Chapter 1: Linear Equations

** 1.2: Gaussian Elimination and Matrices

*** Exercises

**** 1.2.6

$\mathbf{A}$ can be obtained by performing row operations on $\mathbf{B}$ because all row operations are reversible and have an inverse.

**** 1.2.8


$$
\left(\begin{array}{rrr|r}
-1 & 3 & -2 & 1 \\
-1 & 4 & -3 & 0 \\
-1 & 5 & -4 & 0
\end{array}\right) \to
\left(\begin{array}{rrr|r}
-1 & 3 & -2 &  1 \\
 0 & 1 & -1 & -1 \\
 0 & 0 &  0 &  1
\end{array}\right)
$$

There is no $x_3$ that provides a solution for $0x_3 = 1$.

**** 1.2.9

$$
\left(\begin{array}{rrr|r}
-1 & 3 & -2 & 4 \\
-1 & 4 & -3 & 5 \\
-1 & 5 & -4 & 6
\end{array}\right) \to
\left(\begin{array}{rrr|r}
-1 & 3 & -2 &  1 \\
 0 & 1 & -1 & -1 \\
 0 & 0 &  0 &  0
\end{array}\right)
$$

There are many values for $x_3$ that provide a solution for $0x_3 = 0$.

**** 1.2.11

\begin{equation*}
\begin{align}
i_1^{k+1} & = 0.4i_1^k & & & + 0.2i_4^k \\
i_2^{k+1} & = & 0.4i_2^k & + 0.3i_3^k & + 0.2i_4^k \\
i_3^{k+1} & = & 0.3i_2^k & + 0.4i_3^k & + 0.2i_4^k \\
i_4^{k+1} & = 0.6i_1^k & + 0.3i_2^k &+ 0.3i_3^k &+ 0.4i_4^k  \\
\end{align}
\end{equation*}


\begin{equation*}
\begin{pmatrix}
0.4 & 0.0 & 0.0 & 0.2 \\
0.0 & 0.4 & 0.3 & 0.2 \\
0.0 & 0.3 & 0.4 & 0.2 \\
0.6 & 0.3 & 0.3 & 0.4
\end{pmatrix}
\end{equation*}

#+begin_src jupyter-julia :session jl
  A = [0.4 0.0 0.0 0.2;
    0.0 0.4 0.3 0.2;
    0.0 0.3 0.4 0.2;
    0.6 0.3 0.3 0.4]
#+end_src

#+RESULTS:
: 4×4 Matrix{Float64}:
:  0.4  0.0  0.0  0.2
:  0.0  0.4  0.3  0.2
:  0.0  0.3  0.4  0.2
:  0.6  0.3  0.3  0.4

***** (a)

#+begin_src jupyter-julia :session jl
  b = [12.0, 25.0, 26.0, 37.0]
  A \ b
#+end_src

#+RESULTS:
: 4-element Vector{Float64}:
:  10.000000000000016
:  20.000000000000018
:  30.000000000000004
:  39.999999999999964

***** (b)

#+begin_src jupyter-julia :session jl
  x = [20.0; 20.0; 20.0; 40.0]
  A * x
#+end_src

#+RESULTS:
: 4-element Vector{Float64}:
:  16.0
:  22.0
:  22.0
:  40.0

**** 1.2.13

Use the matrix from Example 1.2.1 as the example system

#+begin_src jupyter-julia :session jl
  A = [0.0 1.0 -1.0; -2.0 4.0 -1.0; -2.0 5.0 -4.0]
#+end_src

#+RESULTS:
: 3×3 Matrix{Float64}:
:   0.0  1.0  -1.0
:  -2.0  4.0  -1.0
:  -2.0  5.0  -4.0

#+begin_src jupyter-julia :session jl
  b = [3.0; 1.0; -2.0];
  x = A \ b
  x
#+end_src

#+RESULTS:
: 3-element Vector{Float64}:
:  10.0
:   6.0
:   3.0

***** (a)

Swaps order of the unknown variables

#+begin_src jupyter-julia :session jl
  B = copy(A)
  B[:, 1] = A[:, 2]
  B[:, 2] = A[:, 1]
  B
#+end_src

#+RESULTS:
: 3×3 Matrix{Float64}:
:  1.0   0.0  -1.0
:  4.0  -2.0  -1.0
:  5.0  -2.0  -4.0

#+begin_src jupyter-julia :session jl
  B \ b
#+end_src

#+RESULTS:
: 3-element Vector{Float64}:
:  5.999999999999998
:  9.999999999999998
:  2.999999999999999

***** (b)

Divides unknown variable $x_j$ by $\alpha$.

#+begin_src jupyter-julia :session jl
  B = copy(A)
  B[:, 2] = 2 * A[:, 2]
  B
#+end_src

#+RESULTS:
: 3×3 Matrix{Float64}:
:   0.0   2.0  -1.0
:  -2.0   8.0  -1.0
:  -2.0  10.0  -4.0

#+begin_src jupyter-julia :session jl
  B \ b
#+end_src

#+RESULTS:
: 3-element Vector{Float64}:
:  10.0
:   3.0
:   3.0

***** (c)

Subtracts $\alpha x_j$ from $x_k$.

#+begin_src jupyter-julia :session jl
  B = copy(A)
  α = 4.0
  B[:, 3] = A[:, 3] + α * A[:, 2]
  B
#+end_src

#+RESULTS:
: 3×3 Matrix{Float64}:
:   0.0  1.0   3.0
:  -2.0  4.0  15.0
:  -2.0  5.0  16.0

#+begin_src jupyter-julia :session jl
  B \ b
#+end_src

#+RESULTS:
: 3-element Vector{Float64}:
:  10.0
:  -6.0
:   3.0

#+begin_src jupyter-julia :session jl
  x[2] - α * x[3]
#+end_src

#+RESULTS:
: -6.0

**** 1.2.14

$h_{i,j} = \frac{1}{i + j - 1}$

#+begin_src jupyter-julia :session jl
  n = 3
  H = [1.0 / (i + j - 1.0) for i in 1:n, j in 1:n]
#+end_src

#+RESULTS:
: 3×3 Matrix{Float64}:
:  1.0       0.5       0.333333
:  0.5       0.333333  0.25
:  0.333333  0.25      0.2
